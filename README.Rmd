---
output: github_document
editor_options: 
  chunk_output_type: console
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "README-"
)
```

# fstArray

**fstArray** provides an on-disk backend for a
[_DelayedArray_](http://bioconductor.org/packages/DelayedArray/) object using 
the [**fst**](https://cran.r-project.org/package=fst) file format. **fstArray** 
provides a convenient way to store matrix-like data in an `.fst` file and 
operate on it using delayed operations and block processing.

The `fst` file format is designed for serializing data frames. Therefore, 
**fstArray** can only handle 2-dimensional arrays (matrices), which it does by 
(ab)using the `fst` file format to store columns of the matrix as columns of 
the serialized data frame. Consequently, **fstArray** is best used for tasks 
where data are processed column-wise (or by all columns at once) and, ideally, 
by processing contiguous rows.

[**HDF5Array**](http://bioconductor.org/packages/HDF5Array/) is the obvious 
alternative to **fstArray**. The `HDF5` file format provides arrays of 
arbitrary dimension and allows alternative chunking and serialization 
strategies to better support arbitrary data access patterns. 

In initial testing I find that **fstArray** is much faster than **HDF5Array** 
at writing data to disk and is generally faster at reading data from disk, 
surprisingly often even when reading data using sub-optimal access patterns.

## Installation

You can install fstArray from github with:

```{r gh-installation, eval = FALSE}
# install.packages("devtools")
devtools::install_github("PeteHaitch/fstarray/")
```

## Example

```{r real_pkg_load, message = FALSE, echo = FALSE}
devtools::load_all()
library(HDF5Array)
library(microbenchmark)
```

```{r fake_pkg_load, message = FALSE, echo = TRUE, eval = FALSE}
library(fstArray)
library(HDF5Array)
library(microbenchmark)
```

Here's a simple example comparing the time to write the data to disk and read 
subsets of the data back into memory using **fstArray** and **HDF5Array**. 
**fstArray** and **HDF5Array** are compared without and with data  
compression[^compression]. To make the results more comparable, we chunk the 
*HDF5Array* by column when using compression, mimicing the storage scheme of 
the *fstArray*. 

[^compression]: The level of compression is the default used by **HDF5Array**, scaled for use with **fstArray**.

The data are a 'long' matrix with 10 million rows and 10 columns filled with 
pseudorandom numbers between 0 and 1.

```{r sim_data}
# Simulate a 'long' matrix with numeric data
nrow <- 1e7
ncol <- 10
x <- matrix(runif(nrow * ncol), 
            ncol = ncol, 
            dimnames = list(NULL, letters[seq_len(ncol)]))
```


**TODO:** Also demonstate on data with better compressibility (e.g. 
sequencing coverage-like data)

### Summary of results

**fstArray** is much faster than **HDF5Array** at writing data to disk,
especially for situations where data compression is desired. 

**fstArray** is slightly-to-noticeably faster than **HDF5Array** when reading 
contiguous rows of data into memory as an ordinary _matrix_, with the 
performance gap increasing when data compression is used. This is the best-case 
data access pattern for a *fstArray*.

As expected, **fstArray** is slower than **HDF5Array** when reading random rows 
of uncompressed data into memory as an ordinary matrix. Surprisingly, however, 
**fstArray** is faster than **HDF5Array** on this test when data compression is 
used.

Finally, the worst-case data access pattern for **fstArray** is reading random 
elements of data into memory as an ordinary vector. Surprisingly, **fstArray** 
is 2x faster than **HDF5Array** on this benchmark.

### Writing data to disk

**TODO**: Revisit text after re-running benchmarking

`writefstArray()` is many times faster than `writeHDF5Array()`, both without or 
with compression. Remarkably, in this case using compression in 
`writefstArray()` comes at no additional time cost, and potentially even a 
speed-up. Also remarkable is that `writefstArray()` must currently coerce the 
matrix, `x`, to a data frame before writing to disk, and yet it is still many 
times faster than `writeHDF5Array()`[^coercion].

[^coercion]: This coercion and its associated costs may be avoided in future versions of **fstArray**, bringing even better performance.

```{r writing_data}

# Compression levels
# NOTE: Amount of HDF5 compression (`level`) is on a scale of {0, 1, ..., 9}
hdf5_compression <- getHDF5DumpCompressionLevel()
hdf5_compression
# NOTE: Amount of fst compression (`compress`) is on a scale of {0, 1, ..., 100}
fst_compression <- as.integer(hdf5_compression / 9 * 101)

# Benchmark writing data to disk
tmp_fst_file <- tempfile(fileext = ".fst")
microbenchmark(
  fst_no_compression = writefstArray(x = x, 
                                     file = tmp_fst_file,
                                     compress = 0),
  fst_compression = writefstArray(x = x, 
                                  file = tmp_fst_file,
                                  compress = fst_compression),
  hdf5_no_compression = writeHDF5Array(x = x, 
                                       chunk_dim = c(nrow(x), 1L),
                                       level = 0),
  hdf5_compression = writeHDF5Array(x = x, 
                                    chunk_dim = c(nrow(x), 1L),
                                    level = hdf5_compression),
  times = 5)
```

### Loading data into memory

**TODO**: Revisit text after re-running benchmarking


We now compare the performance of loading the data into memory as an ordinary
matrix. We first create *fstArray* and *HDF5Array* representations of the data
to be used in this benchmarking:

```{r contruct_DelayedArrays}
# Construct fstArray and HDF5Array instances
# NOTE: Each fst file can only contain one dataset whereas a HDF5 file can 
#       contain multiple datasets
fst_file_no_compression <- tempfile(fileext = ".fst")
fst_array_no_compression <- writefstArray(
  x = x,
  file = fst_file_no_compression,
  compress = 0)
file.size(seed(fst_array_no_compression)@file)

fst_file_compression <- tempfile(fileext = ".fst")
fst_array_compression <- writefstArray(
  x = x,
  file = fst_file_compression,
  compress = fst_compression)
file.size(seed(fst_array_compression)@file)

hdf5_array_no_compression <- writeHDF5Array(x = x,
                                            chunk_dim = c(nrow(x), 1L),
                                            level = 0)
file.size(seed(hdf5_array_no_compression)@file)

hdf5_array_compression <- writeHDF5Array(x = x,
                                         chunk_dim = c(nrow(x), 1L),
                                         level = hdf5_compression)
file.size(seed(hdf5_array_compression)@file)

# All objects contain the same data (noting that HDF5Array cannot currently 
# store dimnames)
all.equal(as.matrix(fst_array_no_compression), 
          as.matrix(fst_array_compression))
all.equal(as.matrix(fst_array_no_compression), 
          as.matrix(hdf5_array_no_compression),
          check.attributes = FALSE)
all.equal(as.matrix(fst_array_no_compression), 
          as.matrix(hdf5_array_compression),
          check.attributes = FALSE)
```

**TODO:** Table of file sizes

#### Loading all data into memory

It is faster to load an entire *fstArray* than an entire *HDF5Array*. This is 
despite **fstArray** currently having to do a coercion from a data frame to a 
matrix when loading data into memory[^coercion].

```{r load_all_data}
# Benchmark loading all data from disk as an ordinary matrix
microbenchmark(
  fst_no_compression = as.matrix(fst_array_no_compression),
  fst_compression = as.matrix(fst_array_compression),
  hdf5_no_compression= as.matrix(hdf5_array_no_compression),
  hdf5_compression = as.matrix(hdf5_array_compression),
  times = 10)
```

#### Loading contiguous rows of data into memory

Now, loading 10,000 contiguous rows from the middle of the matrix. Again, 
using an *fstArray* is a faster than an *HDF5Array*.

```{r load_contiguous_rows}
rows <- 56001:66000
# Benchmark loading 10,000 contiguous rows of data from disk as an ordinary 
# matrix
microbenchmark(
  fst_no_compression = as.matrix(fst_array_no_compression[rows, ]),
  fst_compression = as.matrix(fst_array_compression[rows, ]),
  hdf5_no_compression= as.matrix(hdf5_array_no_compression[rows, ]),
  hdf5_compression = as.matrix(hdf5_array_compression[rows, ]),
  times = 10)
all.equal(as.matrix(fst_array_no_compression[rows, ]),
          as.matrix(fst_array_compression[rows, ]))
all.equal(as.matrix(fst_array_no_compression[rows, ]),
          as.matrix(hdf5_array_no_compression[rows, ]))
all.equal(as.matrix(fst_array_no_compression[rows, ]),
          as.matrix(hdf5_array_compression[rows, ]))
```

#### Loading random rows of data into memory

Finally, we load 1,000 randomly selected rows, the worst data access pattern 
for an *fstArray*. Unsurprisingly, an *fstArray* is slower than *HDF5Array*, 
so algorithms should be designed accordingly when targetting **fstArray**.

```{r load_random_rows}
# Benchmark loading 1,000 random rows of data from disk as an ordinary 
# matrix
rows <- sample(nrow(x), 1000)
microbenchmark(
  fst_no_compression = as.matrix(fst_array_no_compression[rows, ]),
  fst_compression = as.matrix(fst_array_compression[rows, ]),
  hdf5_no_compression= as.matrix(hdf5_array_no_compression[rows, ]),
  hdf5_compression = as.matrix(hdf5_array_compression[rows, ]),
  times = 10)
all.equal(as.matrix(fst_array_no_compression[rows, ]),
          as.matrix(fst_array_compression[rows, ]))
all.equal(as.matrix(fst_array_no_compression[rows, ]),
          as.matrix(hdf5_array_no_compression[rows, ]))
all.equal(as.matrix(fst_array_no_compression[rows, ]),
          as.matrix(hdf5_array_compression[rows, ]))
```

#### Loading random elements of data into memory

```{r random_elements}
# Benchmark loading 100,000 random elements of data from disk as an ordinary 
# vector
elements <- sample(length(x), 100000)
microbenchmark(
  fst_no_compression = fst_array_no_compression[elements],
  fst_compression = fst_array_compression[elements],
  hdf5_no_compression= hdf5_array_no_compression[elements],
  hdf5_compression = hdf5_array_compression[elements],
  times = 10)
all.equal(fst_array_no_compression[elements],
          fst_array_compression[elements])
all.equal(fst_array_no_compression[elements],
          hdf5_array_no_compression[elements])
all.equal(fst_array_no_compression[elements],
          hdf5_array_compression[elements])
```


